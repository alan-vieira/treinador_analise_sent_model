{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção do modelo para análise de sentimentos do Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação de bibliotecas\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import re #expreções regulares (regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1512542155436441600</td>\n",
       "      <td>passar a madrugada vendo elite AMÉM</td>\n",
       "      <td>neutro</td>\n",
       "      <td>passar madrugada vendo elite amém</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1512542146418683904</td>\n",
       "      <td>@joaoluizpedrosa Eu assisti algumas produções da @NetflixES e reparei que a maioria quase não tem negros no elenco… https://t.co/H8kBpauEz8</td>\n",
       "      <td>negativo</td>\n",
       "      <td>@joaoluizpedrosa assisti algumas produções @netflixes reparei maioria quase negros elenco…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1512542140013985796</td>\n",
       "      <td>Aff já terminei a 5° temperada de elite. Kkkk #Elite5</td>\n",
       "      <td>neutro</td>\n",
       "      <td>aff terminei 5° temperada elite kkkk #elite5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1512542138931855365</td>\n",
       "      <td>só tem elite na minha tl e eu nem assisto</td>\n",
       "      <td>neutro</td>\n",
       "      <td>elite tl assisto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1512542132510380034</td>\n",
       "      <td>chorei a ver elite?</td>\n",
       "      <td>neutro</td>\n",
       "      <td>chorei ver elite?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   id  \\\n",
       "0           0  1512542155436441600   \n",
       "1           1  1512542146418683904   \n",
       "2           2  1512542140013985796   \n",
       "3           3  1512542138931855365   \n",
       "4           4  1512542132510380034   \n",
       "\n",
       "                                                                                                                                         tweet  \\\n",
       "0                                                                                                          passar a madrugada vendo elite AMÉM   \n",
       "1  @joaoluizpedrosa Eu assisti algumas produções da @NetflixES e reparei que a maioria quase não tem negros no elenco… https://t.co/H8kBpauEz8   \n",
       "2                                                                                        Aff já terminei a 5° temperada de elite. Kkkk #Elite5   \n",
       "3                                                                                                    só tem elite na minha tl e eu nem assisto   \n",
       "4                                                                                                                          chorei a ver elite?   \n",
       "\n",
       "      label  \\\n",
       "0    neutro   \n",
       "1  negativo   \n",
       "2    neutro   \n",
       "3    neutro   \n",
       "4    neutro   \n",
       "\n",
       "                                                                                  tweet_clean  \n",
       "0                                                           passar madrugada vendo elite amém  \n",
       "1  @joaoluizpedrosa assisti algumas produções @netflixes reparei maioria quase negros elenco…  \n",
       "2                                                aff terminei 5° temperada elite kkkk #elite5  \n",
       "3                                                                            elite tl assisto  \n",
       "4                                                                           chorei ver elite?  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregando o dataset\n",
    "tweets_df = pd.read_csv(\"dataset/twitter_sentiments.csv\")\n",
    "\n",
    "# expandindo o espaço de exibição das celulas do pandas\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizando esses dados do label graficamente:\n",
    "tweets_df.label.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenização especial para tweets\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o objeto que faz a vetorização dos dados de texto:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando o vetorizador nos dados de texto e retorna uma matriz esparsa (contendo vários zeros):\n",
    "freq_tweets = vectorizer.fit_transform(tweets_df['tweet_clean'])\n",
    "type(freq_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Visualizando a matris esparsa\n",
    "print(freq_tweets.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 14038)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando o número de linhas e colunas da matriz:\n",
    "freq_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo de Machine Learning (Naive Bayes):\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets, tweets_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Um pequeno teste para demonstrar o funcionamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo instâncias de teste dentro de uma lista:\n",
    "testes = [\n",
    "    'Ai eu tava vendo uma foto tirada do céu de marte,  todo feliz, pensando: meu Deus, quanta vida tem nisso tudo!',\n",
    "    'acabei de ter um mestrado e coincidentemente paulo guedes tirou 92% dos investimentos em ciência',\n",
    "    'Prefeito visita stands no último dia da Semana Nacional de Ciência e Tecnologia',\n",
    "    'Titan e jojo jogaram muito mal a lane phase',\n",
    "    'deus abençoe a rockstar'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Transformando os dados de teste em vetores de palavras:\n",
    "freq_testes = vectorizer.transform(testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ai eu tava vendo uma foto tirada do céu de marte,  todo feliz, pensando: meu Deus, quanta vida tem nisso tudo!, positivo\n",
      "acabei de ter um mestrado e coincidentemente paulo guedes tirou 92% dos investimentos em ciência, positivo\n",
      "Prefeito visita stands no último dia da Semana Nacional de Ciência e Tecnologia, negativo\n",
      "Titan e jojo jogaram muito mal a lane phase, negativo\n",
      "deus abençoe a rockstar, positivo\n"
     ]
    }
   ],
   "source": [
    "# Fazendo a classificação com o modelo treinado:\n",
    "for t, c in zip (testes,modelo.predict(freq_testes)):\n",
    "    # 't' representa o tweet e 'c' a classificação de cada tweet.\n",
    "    print(\"%s, %s\" %(t, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negativo' 'neutro' 'positivo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.42, 0.  , 0.58],\n",
       "       [0.03, 0.07, 0.9 ],\n",
       "       [0.6 , 0.04, 0.35],\n",
       "       [0.97, 0.  , 0.03],\n",
       "       [0.1 , 0.05, 0.85]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilidades de cada classe:\n",
    "print (modelo.classes_)\n",
    "modelo.predict_proba(freq_testes).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fim do pequeno teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos preparar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para aplicar as tags de negação:\n",
    "def marque_negacao(texto):\n",
    "    negacoes = ['não','not']\n",
    "    negacao_detectada = False\n",
    "    resultado = []\n",
    "    palavras = texto.split()\n",
    "    for p in palavras:\n",
    "        p = p.lower()\n",
    "        if negacao_detectada == True:\n",
    "            p = p + '_NEG'\n",
    "        if p in negacoes:\n",
    "            negacao_detectada = True\n",
    "        resultado.append(p)\n",
    "    return (\" \".join(resultado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando modelos com Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('counts', CountVectorizer()), ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vetorizando os dados e passando o classificador:\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_simples = Pipeline([\n",
    "  ('counts', CountVectorizer()),\n",
    "  ('classifier', MultinomialNB())\n",
    "])\n",
    "pipeline_simples.fit(tweets_df.tweet_clean,tweets_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('counts',\n",
       "                 CountVectorizer(tokenizer=<function <lambda> at 0x00000238659809D0>)),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline que atribui tag de negações nas palavras(vetorizador com tag de negação):\n",
    "pipeline_negacoes = Pipeline([\n",
    "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
    "  ('classifier', MultinomialNB())\n",
    "])\n",
    "pipeline_negacoes.fit(tweets_df.tweet_clean,tweets_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um modelo com SVM (Support Vector Machine)\n",
    "from sklearn import svm\n",
    "\n",
    "# Pipeline simples (vetorizador com SVM):\n",
    "pipeline_svm_simples = Pipeline([\n",
    "  ('counts', CountVectorizer()),\n",
    "  ('classifier', svm.SVC(kernel='linear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline com tag de negação (vetoriazador com tag de negação e SVM):\n",
    "pipeline_svm_negacoes = Pipeline([\n",
    "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
    "  ('classifier', svm.SVC(kernel='linear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validando os Modelos com Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fazendo o cross validation do modelo (pipeline_simples):\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "resultados = cross_val_predict(pipeline_simples, tweets_df.tweet_clean,tweets_df.label, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.795"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medindo a acurácia média do modelo (pipeline_simples):\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(tweets_df.label, resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positivo       0.72      0.85      0.78      4369\n",
      "    negativo       0.83      0.78      0.81      4340\n",
      "      neutro       0.87      0.74      0.80      3291\n",
      "\n",
      "    accuracy                           0.80     12000\n",
      "   macro avg       0.81      0.79      0.80     12000\n",
      "weighted avg       0.80      0.80      0.80     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Medidas de validação do modelo (pipeline_simples):\n",
    "sentimento=['positivo', 'negativo', 'neutro']\n",
    "print (metrics.classification_report(tweets_df.label, resultados, target_names=sentimento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   negativo  neutro  positivo    All\n",
      "Real                                       \n",
      "negativo      3699     453       217   4369\n",
      "neutro         795    3390       155   4340\n",
      "positivo       613     227      2451   3291\n",
      "All           5107    4070      2823  12000\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusão (pipeline_simples):\n",
    "print (pd.crosstab(tweets_df.label, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatizando a o processo de validação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para automatizar todo o processo para medir a acurácia:\n",
    "def acuracia(modelo, tweets, classes):\n",
    "  resultados = cross_val_predict(modelo, tweets, classes, cv=10)\n",
    "  return 'Acurácia do modelo: {}'.format(metrics.accuracy_score(classes, resultados))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos visualizar a acurácia para cada modelo criado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Acurácia do modelo: 0.795'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes simples:\n",
    "acuracia(pipeline_simples,tweets_df.tweet_clean,tweets_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Acurácia do modelo: 0.5146666666666667'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes com tag de negacoes:\n",
    "acuracia(pipeline_negacoes,tweets_df.tweet_clean,tweets_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Acurácia do modelo: 0.8774166666666666'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM linear simples:\n",
    "acuracia(pipeline_svm_simples, tweets_df.tweet_clean, tweets_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Acurácia do modelo: 0.5710833333333334'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM linear com tag de negacoes:\n",
    "acuracia(pipeline_svm_negacoes, tweets_df.tweet_clean, tweets_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo com a Tag de Negações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\alsvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cross validation do modelo (pipeline_negacoes):\n",
    "resultados = cross_val_predict(pipeline_negacoes, tweets_df.tweet_clean, tweets_df.label, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5146666666666667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medindo a acurácia do modelo (pipeline_negacoes):\n",
    "metrics.accuracy_score(tweets_df.label, resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positivo       0.48      0.62      0.54      4369\n",
      "    negativo       0.57      0.49      0.52      4340\n",
      "      neutro       0.51      0.41      0.45      3291\n",
      "\n",
      "    accuracy                           0.51     12000\n",
      "   macro avg       0.52      0.51      0.51     12000\n",
      "weighted avg       0.52      0.51      0.51     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Medidas de validação do modelo (pipeline_negacoes):\n",
    "sentimento=['positivo','negativo','neutro']\n",
    "print (metrics.classification_report(tweets_df.label, resultados, target_names=sentimento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   negativo  neutro  positivo    All\n",
      "Real                                       \n",
      "negativo      2715     969       685   4369\n",
      "neutro        1635    2119       586   4340\n",
      "positivo      1287     662      1342   3291\n",
      "All           5637    3750      2613  12000\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusão do modelo (pipeline_negacoes):\n",
    "print (pd.crosstab(tweets_df.label, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando modelo com Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigrams (Naive Bayes multinominal):\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "freq_tweets = vectorizer.fit_transform(tweets_df.tweet_clean)\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,tweets_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation (Naive Bayes multinominal):\n",
    "resultados = cross_val_predict(modelo, freq_tweets, tweets_df.label, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7529166666666667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medindo a acurácia do modelo (Naive Bayes multinominal):\n",
    "metrics.accuracy_score(tweets_df.label, resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positivo       0.84      0.65      0.73      4369\n",
      "    negativo       0.68      0.87      0.76      4340\n",
      "      neutro       0.80      0.75      0.77      3291\n",
      "\n",
      "    accuracy                           0.75     12000\n",
      "   macro avg       0.77      0.75      0.75     12000\n",
      "weighted avg       0.77      0.75      0.75     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Medidas de validação do modelo (Naive Bayes multinominal):\n",
    "sentimento=['positivo','negativo', 'neutro']\n",
    "print (metrics.classification_report(tweets_df.label, resultados, target_names=sentimento))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0426e12addcd0a473080f4add0212d20f941108cd6d9607c25153cd3c0f49f14"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
